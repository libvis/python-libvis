{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:17:28.880477Z",
     "start_time": "2020-05-18T03:17:28.395013Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:13:45.684050Z",
     "start_time": "2020-05-18T03:13:45.675161Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:13:48.017606Z",
     "start_time": "2020-05-18T03:13:47.943875Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:13:58.285340Z",
     "start_time": "2020-05-18T03:13:52.560576Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "epochs=5\n",
    "batch_size=2000\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:14:02.864032Z",
     "start_time": "2020-05-18T03:14:00.590184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92ed7fefe744050a6e737408f048e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Using downloaded and verified file: ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Using downloaded and verified file: ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Using downloaded and verified file: ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/tensor_numpy.cpp:135: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:16:20.003989Z",
     "start_time": "2020-05-18T03:14:05.007692Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.308403\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.054902\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.982284\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.798283\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.322957\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.510801\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.086091\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.196356\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.415741\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.356175\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.584401\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.040999\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.910319\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.998648\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.825030\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.674228\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.527280\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.477173\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.471813\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.451886\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.452869\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.424630\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.389820\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.423868\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.383903\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.375326\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.386491\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.414751\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.414277\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.399219\n",
      "\n",
      "Test set: Average loss: 0.2406, Accuracy: 9304/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.362289\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.319744\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.303148\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.287971\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.305812\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.268230\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.291436\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.291979\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.306838\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.244780\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.285383\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.244813\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.267439\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.269836\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.250329\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.240980\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.211554\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.220715\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.253274\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.240258\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.244713\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.240208\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.227089\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.214748\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.217095\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.234515\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.260419\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.295133\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.222885\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.218094\n",
      "\n",
      "Test set: Average loss: 0.1191, Accuracy: 9621/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.172000\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.185654\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.180177\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.200545\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.238970\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.240464\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.223275\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.279464\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.197536\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.171182\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.141858\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.178473\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.180937\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.184873\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.191437\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.151033\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.162698\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.165710\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.145099\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.146294\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.155939\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.142161\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.147856\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.163189\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.126869\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.137616\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.148988\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.134262\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.156044\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.140257\n",
      "\n",
      "Test set: Average loss: 0.0805, Accuracy: 9741/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.148708\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.147522\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.130085\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.169852\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.137578\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.131836\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.131549\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.138939\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.134850\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.099889\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.130434\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.107505\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.103454\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.109751\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.112074\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.108961\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.168029\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.217554\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.202468\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.180628\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.172250\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.161418\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.137266\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.167125\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.108001\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.117209\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.112611\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.104899\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.100204\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.126107\n",
      "\n",
      "Test set: Average loss: 0.0656, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.101863\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.083986\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.093801\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.109316\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.087035\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.082164\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.091420\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.110443\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.088653\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.098466\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.106072\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.116973\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.075653\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.114005\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.108507\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.096036\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.094743\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.094292\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.092878\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.103255\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.087870\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.086954\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.113454\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.097217\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.127654\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.099979\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.108711\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.122581\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.113540\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.096065\n",
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 9824/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adadelta(model.parameters())\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:19:18.066389Z",
     "start_time": "2020-05-18T03:19:16.066349Z"
    }
   },
   "outputs": [],
   "source": [
    "for b in test_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:20:04.528346Z",
     "start_time": "2020-05-18T03:20:04.150971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8a4b569d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPOElEQVR4nO3df4xV9ZnH8c/D8BuLMrLiiEi12Ii7iWhm0VVc2TXLoq1it42V7lqaGKfNSqpda9dostXUZI3xR8zWdjOtrCgVY9eq2LBbkTSyuvHH6CIiVLEI6uzAYGkLsuXHzDz7xxzaUeZ873DP/cU871cyufee5557npzw4dx7v+eer7m7AAx/I+rdAIDaIOxAEIQdCIKwA0EQdiCIkbXc2Ggb42M1oZabBELZqz3a7/tssFqhsJvZfEn3SmqS9EN3vz31/LGaoLPtwiKbBJDwoq/OrZX9Nt7MmiTdJ+kiSadLWmhmp5f7egCqq8hn9tmS3nb3ze6+X9IjkhZUpi0AlVYk7FMlvTfg8fvZso8wszYz6zCzjgPaV2BzAIqo+rfx7t7u7q3u3jpKY6q9OQA5ioS9U9K0AY9PzJYBaEBFwv6ypFPN7GQzGy3pCkkrKtMWgEore+jN3XvMbLGkn6l/6G2Ju79Rsc4AVFShcXZ3XylpZYV6AVBFnC4LBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIVmcUVjGDn1hNzar+aelFz315f+X7L+5vkPJuvdvXuS9b/+5xtya0dvPZBcd1xn+rX71m5I1vFRhcJuZlsk7ZbUK6nH3Vsr0RSAyqvEkf0v3P2DCrwOgCriMzsQRNGwu6SnzewVM2sb7Alm1mZmHWbWcUD7Cm4OQLmKvo2f4+6dZnacpFVm9gt3XzPwCe7eLqldkiZasxfcHoAyFTqyu3tndtst6XFJsyvRFIDKKzvsZjbBzD5x8L6keZLWV6oxAJVV5G38FEmPm9nB13nY3f+zIl0F03Rsc7L+zuLTkvU7r1ySW5s3Lj1WXUqvW7I+acTYZP2lm/+l7G2/dWB/sn7VhiuT9WMu3ZJb856eclo6opUddnffLOmMCvYCoIoYegOCIOxAEIQdCIKwA0EQdiAIfuJaA3svSZ9r9I27H07WPzN+VSXbOWJ8etToZP35Mx5N1j8z68v5xY54p4RwZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnrwA784+T9W/dk74c8/xx6cs5v7K/L1m/7d1LcmubV56SXHf6si3JejVtuK0lWX9rXnuh19/0t0fl1mZ0FHrpIxJHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2Cpi/7PlkvdTlnNveuyBZf/ebM5L1Ec+tza1N1bbkutW+oHLT6Z/Ord36Z09WddvjOzmWDcTeAIIg7EAQhB0IgrADQRB2IAjCDgRB2IEgGGevgPPHv5Wsjyixm3/xm+OS9aN//btkvTdZra4RZ8xM1tv+/anc2iXjd5V49fR00Re8/oVk/YQ7/7vE68dS8shuZkvMrNvM1g9Y1mxmq8xsU3Y7qbptAihqKG/jH5A0/2PLbpS02t1PlbQ6ewyggZUMu7uvkbTzY4sXSFqa3V8q6bIK9wWgwsr9zD7F3buy+9skTcl7opm1SWqTpLEaX+bmABRV+Nt4d3dJnqi3u3uru7eO0piimwNQpnLDvt3MWiQpu+2uXEsAqqHcsK+QtCi7v0hSdX+rCKAw638XnniC2XJJcyVNlrRd0rclPSHpUUknSdoq6XJ3//iXeIeYaM1+tl1YsOXG0/335ybrt/3DkmS91HXjF239y2R9w0P5Y91TlqXnIe/bvTtZtzHpj15nvZA+B+DW4/4nWU85/7UvJuvNi36brPfu2FH2to9UL/pq7fKdg56gUPILOndfmFMafqkFhjFOlwWCIOxAEIQdCIKwA0EQdiCIkkNvlTRch95K2fvZ2cn6u59Nr//MRXcn6yeNHJdbu/Z/z0uu23Hfmcn6by9KXwZ7/Zx/S9ZTFnfOSdY333Basj7i2fKH9Yar1NAbR3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJx9iPAyJOnJ+ub75iYW1t37gOFtj2ixOWc+/IvUiRJeqdnb27t6sXfSK479qmXknUcinF2AIQdiIKwA0EQdiAIwg4EQdiBIAg7EARTNh8Bet7Zmqyf8vXjc2szv3lNct2NV9xXVk9D9fnv3pBbO+EpplSuJY7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+zDQE/Xttza6OmTk+uW+r16k5U4HnhfsnzL1ctya3e+/6XkuhOXv5DeNg5LySO7mS0xs24zWz9g2S1m1mlma7O/i6vbJoCihvI2/gFJ8wdZfo+7z8r+Vla2LQCVVjLs7r5G0s4a9AKgiop8QbfYzNZlb/Mn5T3JzNrMrMPMOg5oX4HNASii3LB/X9KnJM2S1CXprrwnunu7u7e6e+sojSlzcwCKKivs7r7d3XvdvU/SDySlpykFUHdlhd3MWgY8/Jyk9XnPBdAYSo6zm9lySXMlTTaz9yV9W9JcM5slySVtkfTVKvaIEvZ84ezc2kvn3Jtct0+jkvUP+36XrN/cNTdZv+eE/N+s/+afnkiu+0NdlqwzDn94Sobd3RcOsvj+KvQCoIo4XRYIgrADQRB2IAjCDgRB2IEg+InrMLBzZlNubYylh9ZKufRr1ybr459Zl6yf99gVubXnZz2SXPeYWx9O1u9/bbDfZ/1B74a3kvVoOLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMsx8BmmacnKxf/6WflP3aX/xleqx67E9fStbTF5KWjv38e7m1c3482A8q/+CFs5Yn69+6aUKyPuPvkuVwOLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMsx8B3v7OxGT9yxM7c2uP72lOrrv3b0qNlBfTt3dvbu34r6enA3v+mfRv8f/j/O8m69fN/EpurXfjpuS6wxFHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2BtA0+dhk/Y7Wx5L1EbLc2o6e9Bh97we/Starqeedrcn6oztnJ+vfm5qesnnPjEm5tbEbk6sOSyWP7GY2zcx+bmYbzOwNM7s2W95sZqvMbFN2m79nAdTdUN7G90i63t1Pl3SOpGvM7HRJN0pa7e6nSlqdPQbQoEqG3d273P3V7P5uSRslTZW0QNLS7GlLJV1WrSYBFHdYn9nN7JOSzpT0oqQp7t6VlbZJmpKzTpukNkkaq/Hl9gmgoCF/G29mR0l6TNJ17r5rYM3dXZIPtp67t7t7q7u3jtKYQs0CKN+Qwm5mo9Qf9B+5+8FLmW43s5as3iKpuzotAqiEkm/jzcwk3S9po7vfPaC0QtIiSbdnt09WpcMIpkxOlqeN3Jms9yl/yuYVXWck17UxO5J135f+GWoRTcccnayPHrEnWe/19M9zd03P/+c9Nrnm8DSUz+znSbpS0utmtjZbdpP6Q/6omV0laauky6vTIoBKKBl2d39Oyj1r48LKtgOgWjhdFgiCsANBEHYgCMIOBEHYgSD4iWsD6H3jzWT9O+9ekqz/eMbK3NpPT0uf/vC1Zy9I1tdsnpmse+e4ZP3EM7pya1dOS/9ENXWJbElau783WW/52bbcWnrN4YkjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTj7EWDn3dOT9afvmpBbmzcu/Zvwf532bLI+YtqaZL1v8AsUVcTGAweS9cufuC5Zn7EpPY4fDUd2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQjC+idzqY2J1uxnGxekrbSRLcfn1ja3nZJct3fmh4W23f6ny5L1h3acm1v7ry3p3k54MD2D0JiVLyfrEb3oq7XLdw56NWiO7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQRMlxdjObJulBSVMkuaR2d7/XzG6RdLWkgxN83+Tu+RcwF+PsQLWlxtmHcvGKHknXu/urZvYJSa+Y2aqsdo+731mpRgFUz1DmZ++S1JXd321mGyVNrXZjACrrsD6zm9knJZ0p6cVs0WIzW2dmS8xsUs46bWbWYWYdB7SvULMAyjfksJvZUZIek3Sdu++S9H1Jn5I0S/1H/rsGW8/d29291d1bRyl9rjOA6hlS2M1slPqD/iN3/4kkuft2d+919z5JP5A0u3ptAiiqZNjNzCTdL2mju989YHnLgKd9TtL6yrcHoFKG8m38eZKulPS6ma3Nlt0kaaGZzVL/cNwWSV+tSocAKmIo38Y/J2mwcbvkmDqAxsIZdEAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSBqOmWzme2QtHXAosmSPqhZA4enUXtr1L4keitXJXub7u5/NFihpmE/ZONmHe7eWrcGEhq1t0btS6K3ctWqN97GA0EQdiCIeoe9vc7bT2nU3hq1L4neylWT3ur6mR1A7dT7yA6gRgg7EERdwm5m883sTTN728xurEcPecxsi5m9bmZrzayjzr0sMbNuM1s/YFmzma0ys03Z7aBz7NWpt1vMrDPbd2vN7OI69TbNzH5uZhvM7A0zuzZbXtd9l+irJvut5p/ZzaxJ0luS/krS+5JelrTQ3TfUtJEcZrZFUqu71/0EDDP7c0kfSnrQ3f8kW3aHpJ3ufnv2H+Ukd//HBuntFkkf1nsa72y2opaB04xLukzSV1THfZfo63LVYL/V48g+W9Lb7r7Z3fdLekTSgjr00fDcfY2knR9bvEDS0uz+UvX/Y6m5nN4agrt3ufur2f3dkg5OM17XfZfoqybqEfapkt4b8Ph9NdZ87y7paTN7xcza6t3MIKa4e1d2f5ukKfVsZhAlp/GupY9NM94w+66c6c+L4gu6Q81x97MkXSTpmuztakPy/s9gjTR2OqRpvGtlkGnGf6+e+67c6c+LqkfYOyVNG/D4xGxZQ3D3zuy2W9LjarypqLcfnEE3u+2ucz+/10jTeA82zbgaYN/Vc/rzeoT9ZUmnmtnJZjZa0hWSVtShj0OY2YTsixOZ2QRJ89R4U1GvkLQou79I0pN17OUjGmUa77xpxlXnfVf36c/dveZ/ki5W/zfyv5R0cz16yOnrFEmvZX9v1Ls3ScvV/7bugPq/27hK0rGSVkvaJOkZSc0N1NtDkl6XtE79wWqpU29z1P8WfZ2ktdnfxfXed4m+arLfOF0WCIIv6IAgCDsQBGEHgiDsQBCEHQiCsANBEHYgiP8HI6OQdtNYnjkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(b[0].detach().cpu().numpy()[0,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:23:02.238044Z",
     "start_time": "2020-05-18T03:23:02.124092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6714e+01, -1.4054e+01, -8.8363e+00, -8.9068e+00, -1.5691e+01,\n",
       "         -1.3380e+01, -1.6269e+01, -1.1996e+01, -2.9278e-04, -1.2580e+01]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(b[0].to(device)[:1])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:23:12.698031Z",
     "start_time": "2020-05-18T03:23:12.434473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(10), res.detach().cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T03:26:30.940568Z",
     "start_time": "2020-05-18T03:26:30.896680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : 288\n",
      "conv1.bias : 32\n",
      "conv2.weight : 18432\n",
      "conv2.bias : 64\n",
      "fc1.weight : 1179648\n",
      "fc1.bias : 128\n",
      "fc2.weight : 1280\n",
      "fc2.bias : 10\n"
     ]
    }
   ],
   "source": [
    "p = list(model.named_parameters())\n",
    "for x in p:\n",
    "    print(x[0],':', torch.numel(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1778,  0.2160, -0.1562],\n",
       "          [-0.2498,  0.3287,  0.3338],\n",
       "          [ 0.0827,  0.1157, -0.2219]]],\n",
       "\n",
       "\n",
       "        [[[-0.0362, -0.1317, -0.0864],\n",
       "          [ 0.2682,  0.3209,  0.1445],\n",
       "          [ 0.0390, -0.1257,  0.2463]]],\n",
       "\n",
       "\n",
       "        [[[-0.1711, -0.1340, -0.1410],\n",
       "          [ 0.0288, -0.2328,  0.2236],\n",
       "          [ 0.0702,  0.2597,  0.0077]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2867,  0.4020, -0.2208],\n",
       "          [ 0.2556,  0.3275,  0.1281],\n",
       "          [ 0.0071, -0.3357, -0.2546]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1315,  0.0074, -0.1273],\n",
       "          [ 0.1005,  0.2866, -0.3804],\n",
       "          [ 0.0958, -0.1048,  0.0318]]],\n",
       "\n",
       "\n",
       "        [[[-0.5412, -0.0485,  0.3391],\n",
       "          [-0.3502,  0.2956,  0.1419],\n",
       "          [-0.3551,  0.0093,  0.3081]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1048, -0.0904, -0.0148],\n",
       "          [-0.0435,  0.0599, -0.0093],\n",
       "          [ 0.2936, -0.1868,  0.1078]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1351,  0.1152,  0.1770],\n",
       "          [ 0.0157,  0.1192, -0.2279],\n",
       "          [-0.3656, -0.1112, -0.1889]]],\n",
       "\n",
       "\n",
       "        [[[-0.0725, -0.3036,  0.0143],\n",
       "          [-0.1931,  0.2000, -0.2366],\n",
       "          [-0.0911, -0.1347, -0.2952]]],\n",
       "\n",
       "\n",
       "        [[[-0.1673,  0.2577,  0.2343],\n",
       "          [-0.0008, -0.0570, -0.2153],\n",
       "          [ 0.2743,  0.2079,  0.3027]]],\n",
       "\n",
       "\n",
       "        [[[-0.0391,  0.1562, -0.3617],\n",
       "          [-0.0091,  0.0614,  0.0162],\n",
       "          [ 0.1600,  0.2674, -0.2483]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3329,  0.3370, -0.2914],\n",
       "          [ 0.1450,  0.0102, -0.3506],\n",
       "          [ 0.0598, -0.0905, -0.3957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2493, -0.0071,  0.3049],\n",
       "          [-0.0827,  0.1865, -0.2122],\n",
       "          [ 0.1286,  0.1232,  0.2288]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1191,  0.0267,  0.0968],\n",
       "          [-0.2271, -0.2192, -0.2884],\n",
       "          [-0.1599,  0.2858,  0.0209]]],\n",
       "\n",
       "\n",
       "        [[[-0.0817,  0.2809,  0.2605],\n",
       "          [-0.0221,  0.2682, -0.1269],\n",
       "          [-0.1429, -0.1116, -0.3195]]],\n",
       "\n",
       "\n",
       "        [[[-0.0819,  0.3778,  0.0202],\n",
       "          [ 0.1739,  0.1363, -0.0012],\n",
       "          [-0.3489, -0.3575,  0.0406]]],\n",
       "\n",
       "\n",
       "        [[[-0.1314,  0.2159,  0.1530],\n",
       "          [-0.1689,  0.1616, -0.0248],\n",
       "          [ 0.2859, -0.1216,  0.0403]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3154,  0.1205, -0.2267],\n",
       "          [-0.1109,  0.3237, -0.4001],\n",
       "          [ 0.0810,  0.3062, -0.2348]]],\n",
       "\n",
       "\n",
       "        [[[-0.4490, -0.0024,  0.1762],\n",
       "          [-0.0358, -0.2012,  0.2037],\n",
       "          [ 0.0058,  0.3777,  0.3293]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1630,  0.3279, -0.1422],\n",
       "          [-0.3037,  0.0764, -0.0067],\n",
       "          [ 0.1142,  0.1337, -0.1837]]],\n",
       "\n",
       "\n",
       "        [[[-0.1987, -0.2690, -0.2858],\n",
       "          [ 0.1409, -0.1916, -0.0916],\n",
       "          [ 0.3895,  0.2728,  0.3916]]],\n",
       "\n",
       "\n",
       "        [[[-0.1264, -0.0558, -0.1920],\n",
       "          [-0.1465,  0.3094, -0.0359],\n",
       "          [-0.1131, -0.2067, -0.2444]]],\n",
       "\n",
       "\n",
       "        [[[-0.1181, -0.2900, -0.0351],\n",
       "          [ 0.3264, -0.1506, -0.0614],\n",
       "          [-0.0741, -0.1883, -0.2089]]],\n",
       "\n",
       "\n",
       "        [[[-0.1990,  0.2487, -0.0728],\n",
       "          [-0.1477,  0.1522,  0.3045],\n",
       "          [ 0.0184, -0.1880,  0.2854]]],\n",
       "\n",
       "\n",
       "        [[[-0.2976,  0.1022, -0.1767],\n",
       "          [ 0.2894, -0.1087, -0.0093],\n",
       "          [-0.1559, -0.1905,  0.1215]]],\n",
       "\n",
       "\n",
       "        [[[-0.0701,  0.2811, -0.1363],\n",
       "          [-0.2490,  0.2386,  0.2390],\n",
       "          [-0.1874, -0.1967,  0.1680]]],\n",
       "\n",
       "\n",
       "        [[[-0.0293, -0.1162,  0.4149],\n",
       "          [-0.1516, -0.1574,  0.0437],\n",
       "          [ 0.2052, -0.3690, -0.1999]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2418, -0.0802,  0.2624],\n",
       "          [-0.3091,  0.2918,  0.1173],\n",
       "          [ 0.1487, -0.2105, -0.3518]]],\n",
       "\n",
       "\n",
       "        [[[-0.0767, -0.0147, -0.3765],\n",
       "          [ 0.0491,  0.1308, -0.3635],\n",
       "          [ 0.2572,  0.2707,  0.0621]]],\n",
       "\n",
       "\n",
       "        [[[-0.0677, -0.2278, -0.2621],\n",
       "          [-0.2957, -0.0993, -0.2225],\n",
       "          [-0.0217,  0.3688,  0.2987]]],\n",
       "\n",
       "\n",
       "        [[[-0.1884, -0.1029, -0.0569],\n",
       "          [-0.2411, -0.2733,  0.0600],\n",
       "          [-0.0603, -0.1008,  0.2790]]],\n",
       "\n",
       "\n",
       "        [[[-0.0388,  0.0649, -0.1986],\n",
       "          [-0.0792,  0.1431, -0.2773],\n",
       "          [-0.3159, -0.1669, -0.0297]]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = p[0][1]\n",
    "param.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
