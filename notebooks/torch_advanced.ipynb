{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Define-network\" data-toc-modified-id=\"Define-network-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Define network</a></span></li><li><span><a href=\"#Define-train-/-test-functions\" data-toc-modified-id=\"Define-train-/-test-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Define train / test functions</a></span></li><li><span><a href=\"#Create-model\" data-toc-modified-id=\"Create-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create model</a></span></li><li><span><a href=\"#Create-data-loaders\" data-toc-modified-id=\"Create-data-loaders-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create data loaders</a></span></li><li><span><a href=\"#Setup-libvis\" data-toc-modified-id=\"Setup-libvis-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Setup libvis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-function-history-graph\" data-toc-modified-id=\"Loss-function-history-graph-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Loss function history graph</a></span></li><li><span><a href=\"#'Stop-training'-button\" data-toc-modified-id=\"'Stop-training'-button-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>'Stop training' button</a></span></li><li><span><a href=\"#Learning-rate-slider\" data-toc-modified-id=\"Learning-rate-slider-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Learning rate slider</a></span></li><li><span><a href=\"#Callbacks\" data-toc-modified-id=\"Callbacks-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Callbacks</a></span></li></ul></li><li><span><a href=\"#Train-model\" data-toc-modified-id=\"Train-model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Train model</a></span></li><li><span><a href=\"#Resulting-dashboard\" data-toc-modified-id=\"Resulting-dashboard-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Resulting dashboard</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:24.149548Z",
     "start_time": "2020-11-24T08:02:20.104503Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from libvis import Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:24.210880Z",
     "start_time": "2020-11-24T08:02:24.151201Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network\n",
    "\n",
    "Nothing fancy here, just a 2-layer convolutional network to use for MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:24.242528Z",
     "start_time": "2020-11-24T08:02:24.214402Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train / test functions\n",
    "\n",
    "Train and test functions take a callback function and call it after each train batch,\n",
    "passing information about model performance.\n",
    "\n",
    "You can also use a global variable and access it in the train function, but it \n",
    "tends to get messy for many variables.\n",
    "Better to keep visualization part apart from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:24.322543Z",
     "start_time": "2020-11-24T08:02:24.244817Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TrainInfo = namedtuple('TrainInfo', 'epoch optimizer model output loss target pred')\n",
    "\n",
    "def output2pred(output):\n",
    "    \"\"\" Desicion from output of the network. \"\"\"\n",
    "    return output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, callback):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        pred = output2pred(output)\n",
    "        callback_info = TrainInfo(epoch, optimizer, model, output, loss, target, pred)\n",
    "        callback(callback_info)\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, device, test_loader, callback):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output2pred(output)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            callback(data, target, pred, test_loss, output)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T06:41:14.726783Z",
     "start_time": "2020-11-09T06:41:14.724264Z"
    }
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:24.570191Z",
     "start_time": "2020-11-24T08:02:24.488595Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "epochs=5\n",
    "batch_size=2000\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T06:41:14.726783Z",
     "start_time": "2020-11-09T06:41:14.724264Z"
    }
   },
   "source": [
    "## Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:25.721963Z",
     "start_time": "2020-11-24T08:02:25.481116Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:27.659626Z",
     "start_time": "2020-11-24T08:02:27.627496Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adadelta(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:27.391649Z",
     "start_time": "2020-11-24T08:02:26.660834Z"
    }
   },
   "outputs": [],
   "source": [
    "from libvis.modules import Image, uicontrols\n",
    "from libvis import Vis\n",
    "from loguru import logger as log\n",
    "import bokeh\n",
    "import bokeh.plotting\n",
    "\n",
    "# lets mute logs for now\n",
    "log.disable('libvis')\n",
    "log.disable('legimens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:55:58.572529Z",
     "start_time": "2020-11-24T08:55:58.274177Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTPServer start on 7000 failed: [Errno 98] Address already in use\n",
      "Webapp HTTP server failed to start at localhost:7000. To start manually: `Vis.start_http(port)`. Error was: [Errno 98] Address already in use\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/site-packages/trio/_core/_run.py\", line 1804, in run\n",
      "    raise runner.main_task_outcome.error\n",
      "  File \"/home/dali/side-projects-hobby/legimens/python/legimens/App.py\", line 268, in _start\n",
      "    await trio.sleep(CORO_SCHEDULER_DELAY)\n",
      "  File \"/usr/lib/python3.8/site-packages/trio/_core/_run.py\", line 730, in __aexit__\n",
      "    raise combined_error_from_nursery\n",
      "  File \"/home/dali/side-projects-hobby/legimens/python/legimens/websocket/server.py\", line 54, in start_server\n",
      "    await ws_serve(addr, port, handler_func, nursery=nursery)\n",
      "  File \"/home/dali/side-projects-hobby/legimens/python/legimens/websocket/server.py\", line 27, in ws_serve\n",
      "    await serve_websocket(server, addr, port,\n",
      "  File \"/usr/lib/python3.8/site-packages/trio_websocket-0.8.0-py3.8.egg/trio_websocket/_impl.py\", line 369, in serve_websocket\n",
      "  File \"/usr/lib/python3.8/site-packages/trio/_highlevel_open_tcp_listeners.py\", line 133, in open_tcp_listeners\n",
      "    await sock.bind(sockaddr)\n",
      "  File \"/usr/lib/python3.8/site-packages/trio/_socket.py\", line 473, in bind\n",
      "    return self._sock.bind(address)\n",
      "OSError: [Errno 98] Address already in use\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to start Legimens. Reason may be printed above by other thread. Exception sharing is under development.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-46fd06d55594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_poll_delay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/side-projects-hobby/pywebviz/python/libvis/VisWorker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ws_port, vis_port, nb_name, debug, allow_remote)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/side-projects-hobby/pywebviz/python/libvis/VisWorker.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Legimens app is already running, what are you doing? To stop: `Vis.stop()`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/side-projects-hobby/legimens/python/legimens/App.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to start Legimens. Reason may be printed above by other thread. Exception sharing is under development.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failed to start Legimens. Reason may be printed above by other thread. Exception sharing is under development."
     ]
    }
   ],
   "source": [
    "vis = Vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:27.659626Z",
     "start_time": "2020-11-24T08:02:27.627496Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adadelta(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function history graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:28.286714Z",
     "start_time": "2020-11-24T08:02:28.244204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Legi_0x7f63ba2c6180'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = []\n",
    "vis.watch(losses, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:29:42.641952Z",
     "start_time": "2020-11-24T08:29:42.577492Z"
    }
   },
   "source": [
    "### 'Stop training' button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:28.903762Z",
     "start_time": "2020-11-24T08:02:28.877898Z"
    }
   },
   "outputs": [],
   "source": [
    "train_enable = True\n",
    "def disable_train():\n",
    "    \"\"\" Set train_enable flag to false to sto training. \"\"\"\n",
    "    print('Stopping train after this batch')\n",
    "    global train_enable\n",
    "    train_enable = False\n",
    "    \n",
    "vis.vars.stop = uicontrols.Button(label='Stop training', on_press=disable_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:30.545457Z",
     "start_time": "2020-11-24T08:02:30.523289Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = optimizer.param_groups[0]['lr']\n",
    "slider = uicontrols.Slider(value=lr, min=0, max=0.05)\n",
    "vis.vars.lr = slider\n",
    "\n",
    "def on_slider(lr_new):\n",
    "    \"\"\" Change learinng rate of optimizer. \"\"\"\n",
    "    optimizer.param_groups[0]['lr'] = lr_new\n",
    "    print('Changed lr to', lr_new)\n",
    "    \n",
    "vis.vars.lr.on_change = on_slider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:02:31.675168Z",
     "start_time": "2020-11-24T08:02:31.610441Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_callback(info):\n",
    "    global train_enable\n",
    "    loss = info.loss\n",
    "    model = info.model\n",
    "    \n",
    "    v = vis.vars\n",
    "    v.epoch = info.epoch\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    params = [param.grad.flatten() for _, param in model.named_parameters()]\n",
    "    vals = np.concatenate(params)\n",
    "    y, x = np.histogram(vals, bins=200)\n",
    "    v.hist = np.array([x[1:], np.log(y+1)])\n",
    "    \n",
    "    y, x = np.histogram(model.fc2.weight.grad.flatten(), bins=200)\n",
    "    v.hist_fc2_grad = np.array([x[1:], np.log(y+1)])\n",
    "    \n",
    "    y, x = np.histogram(model.fc1.weight.data.flatten(), bins=200)\n",
    "    v.hist_fc1 = np.array([x[1:], np.log(y+1)])\n",
    "    \n",
    "    \n",
    "    confmat = sklearn.metrics.confusion_matrix(info.target, info.pred)\n",
    "    fig = bokeh.plotting.figure(\n",
    "        title='confusion matrix',\n",
    "        sizing_mode='stretch_both'\n",
    "    )\n",
    "    fig.image(image=[confmat], dw=10, dh=10)\n",
    "    v.confusion_matrix = fig \n",
    "    \n",
    "    if not train_enable:\n",
    "        train_enable=True\n",
    "        raise StopIteration()\n",
    "    \n",
    "def test_callback(data, target, pred, loss, output):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T08:08:12.395563Z",
     "start_time": "2020-11-24T08:02:32.884784Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed lr to 0.0465\n",
      "Changed lr to 0.045\n",
      "Changed lr to 0.042\n",
      "Changed lr to 0.0355\n",
      "Changed lr to 0.029\n",
      "Changed lr to 0.028\n",
      "Changed lr to 0.0275\n",
      "Changed lr to 0.025\n",
      "Changed lr to 0.0245\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.318081\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.292238\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.268246\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.246949\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.223495\n",
      "Changed lr to 0.043\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.194132\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.152984\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.106336\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.053347\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.990341\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.928945\n",
      "Changed lr to 0.006\n",
      "Changed lr to 0.0\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.857681\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.843310\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.867097\n",
      "Changed lr to 0.042\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.855610\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8814b6427381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d42e59f18ff1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, callback)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput2pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, train_callback)\n",
    "    test(model, device, test_loader, test_callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T07:22:07.056716Z",
     "start_time": "2020-11-24T07:22:06.750858Z"
    }
   },
   "source": [
    "## Resulting dashboard\n",
    "\n",
    "\n",
    "![](https://libvis.dev/pictures/torch_adv_demo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T07:30:57.754492Z",
     "start_time": "2020-11-24T07:30:57.336242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping webapp http server: `Vis.stop_http()`... OK\n",
      "Stopping websocket server: `Vis.app.stop()`... OK\n"
     ]
    }
   ],
   "source": [
    "vis.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1778,  0.2160, -0.1562],\n",
       "          [-0.2498,  0.3287,  0.3338],\n",
       "          [ 0.0827,  0.1157, -0.2219]]],\n",
       "\n",
       "\n",
       "        [[[-0.0362, -0.1317, -0.0864],\n",
       "          [ 0.2682,  0.3209,  0.1445],\n",
       "          [ 0.0390, -0.1257,  0.2463]]],\n",
       "\n",
       "\n",
       "        [[[-0.1711, -0.1340, -0.1410],\n",
       "          [ 0.0288, -0.2328,  0.2236],\n",
       "          [ 0.0702,  0.2597,  0.0077]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2867,  0.4020, -0.2208],\n",
       "          [ 0.2556,  0.3275,  0.1281],\n",
       "          [ 0.0071, -0.3357, -0.2546]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1315,  0.0074, -0.1273],\n",
       "          [ 0.1005,  0.2866, -0.3804],\n",
       "          [ 0.0958, -0.1048,  0.0318]]],\n",
       "\n",
       "\n",
       "        [[[-0.5412, -0.0485,  0.3391],\n",
       "          [-0.3502,  0.2956,  0.1419],\n",
       "          [-0.3551,  0.0093,  0.3081]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1048, -0.0904, -0.0148],\n",
       "          [-0.0435,  0.0599, -0.0093],\n",
       "          [ 0.2936, -0.1868,  0.1078]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1351,  0.1152,  0.1770],\n",
       "          [ 0.0157,  0.1192, -0.2279],\n",
       "          [-0.3656, -0.1112, -0.1889]]],\n",
       "\n",
       "\n",
       "        [[[-0.0725, -0.3036,  0.0143],\n",
       "          [-0.1931,  0.2000, -0.2366],\n",
       "          [-0.0911, -0.1347, -0.2952]]],\n",
       "\n",
       "\n",
       "        [[[-0.1673,  0.2577,  0.2343],\n",
       "          [-0.0008, -0.0570, -0.2153],\n",
       "          [ 0.2743,  0.2079,  0.3027]]],\n",
       "\n",
       "\n",
       "        [[[-0.0391,  0.1562, -0.3617],\n",
       "          [-0.0091,  0.0614,  0.0162],\n",
       "          [ 0.1600,  0.2674, -0.2483]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3329,  0.3370, -0.2914],\n",
       "          [ 0.1450,  0.0102, -0.3506],\n",
       "          [ 0.0598, -0.0905, -0.3957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2493, -0.0071,  0.3049],\n",
       "          [-0.0827,  0.1865, -0.2122],\n",
       "          [ 0.1286,  0.1232,  0.2288]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1191,  0.0267,  0.0968],\n",
       "          [-0.2271, -0.2192, -0.2884],\n",
       "          [-0.1599,  0.2858,  0.0209]]],\n",
       "\n",
       "\n",
       "        [[[-0.0817,  0.2809,  0.2605],\n",
       "          [-0.0221,  0.2682, -0.1269],\n",
       "          [-0.1429, -0.1116, -0.3195]]],\n",
       "\n",
       "\n",
       "        [[[-0.0819,  0.3778,  0.0202],\n",
       "          [ 0.1739,  0.1363, -0.0012],\n",
       "          [-0.3489, -0.3575,  0.0406]]],\n",
       "\n",
       "\n",
       "        [[[-0.1314,  0.2159,  0.1530],\n",
       "          [-0.1689,  0.1616, -0.0248],\n",
       "          [ 0.2859, -0.1216,  0.0403]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3154,  0.1205, -0.2267],\n",
       "          [-0.1109,  0.3237, -0.4001],\n",
       "          [ 0.0810,  0.3062, -0.2348]]],\n",
       "\n",
       "\n",
       "        [[[-0.4490, -0.0024,  0.1762],\n",
       "          [-0.0358, -0.2012,  0.2037],\n",
       "          [ 0.0058,  0.3777,  0.3293]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1630,  0.3279, -0.1422],\n",
       "          [-0.3037,  0.0764, -0.0067],\n",
       "          [ 0.1142,  0.1337, -0.1837]]],\n",
       "\n",
       "\n",
       "        [[[-0.1987, -0.2690, -0.2858],\n",
       "          [ 0.1409, -0.1916, -0.0916],\n",
       "          [ 0.3895,  0.2728,  0.3916]]],\n",
       "\n",
       "\n",
       "        [[[-0.1264, -0.0558, -0.1920],\n",
       "          [-0.1465,  0.3094, -0.0359],\n",
       "          [-0.1131, -0.2067, -0.2444]]],\n",
       "\n",
       "\n",
       "        [[[-0.1181, -0.2900, -0.0351],\n",
       "          [ 0.3264, -0.1506, -0.0614],\n",
       "          [-0.0741, -0.1883, -0.2089]]],\n",
       "\n",
       "\n",
       "        [[[-0.1990,  0.2487, -0.0728],\n",
       "          [-0.1477,  0.1522,  0.3045],\n",
       "          [ 0.0184, -0.1880,  0.2854]]],\n",
       "\n",
       "\n",
       "        [[[-0.2976,  0.1022, -0.1767],\n",
       "          [ 0.2894, -0.1087, -0.0093],\n",
       "          [-0.1559, -0.1905,  0.1215]]],\n",
       "\n",
       "\n",
       "        [[[-0.0701,  0.2811, -0.1363],\n",
       "          [-0.2490,  0.2386,  0.2390],\n",
       "          [-0.1874, -0.1967,  0.1680]]],\n",
       "\n",
       "\n",
       "        [[[-0.0293, -0.1162,  0.4149],\n",
       "          [-0.1516, -0.1574,  0.0437],\n",
       "          [ 0.2052, -0.3690, -0.1999]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2418, -0.0802,  0.2624],\n",
       "          [-0.3091,  0.2918,  0.1173],\n",
       "          [ 0.1487, -0.2105, -0.3518]]],\n",
       "\n",
       "\n",
       "        [[[-0.0767, -0.0147, -0.3765],\n",
       "          [ 0.0491,  0.1308, -0.3635],\n",
       "          [ 0.2572,  0.2707,  0.0621]]],\n",
       "\n",
       "\n",
       "        [[[-0.0677, -0.2278, -0.2621],\n",
       "          [-0.2957, -0.0993, -0.2225],\n",
       "          [-0.0217,  0.3688,  0.2987]]],\n",
       "\n",
       "\n",
       "        [[[-0.1884, -0.1029, -0.0569],\n",
       "          [-0.2411, -0.2733,  0.0600],\n",
       "          [-0.0603, -0.1008,  0.2790]]],\n",
       "\n",
       "\n",
       "        [[[-0.0388,  0.0649, -0.1986],\n",
       "          [-0.0792,  0.1431, -0.2773],\n",
       "          [-0.3159, -0.1669, -0.0297]]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = p[0][1]\n",
    "param.data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
